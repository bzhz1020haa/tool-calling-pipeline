import json
import re
import argparse
from pathlib import Path
from collections import deque


THINK_RE = re.compile(r"<think>[\s\S]*?</think>", re.IGNORECASE)
TOOL_CALL_RE = re.compile(r"<tool_call>([\s\S]*?)</tool_call>", re.IGNORECASE)
TOOL_RESPONSE_RE = re.compile(r"<tool_response>([\s\S]*?)</tool_response>", re.IGNORECASE)


def extract_calls_responses_and_text(assistant_text: str):
    """ä»æ–‡æœ¬ä¸­æå–æŒ‰é¡ºåºå‡ºç°çš„ tool_call ä¸ tool_response ç‰‡æ®µï¼Œå¹¶è¿”å›å»æ ‡ç­¾åçš„å‰©ä½™æ–‡æœ¬ã€‚
    è¿”å› (calls: list[str], responses: list[str], remainder: str)
    """
    if not isinstance(assistant_text, str):
        return [], [], ""

    text_wo_think = THINK_RE.sub("", assistant_text)

    calls = [m.group(1).strip() for m in TOOL_CALL_RE.finditer(text_wo_think)]
    responses = [m.group(1).strip() for m in TOOL_RESPONSE_RE.finditer(text_wo_think)]
    remainder = TOOL_RESPONSE_RE.sub("", TOOL_CALL_RE.sub("", text_wo_think)).strip()
    return calls, responses, remainder


def parse_tool_name_from_call(call_str: str) -> str:
    """ä» tool_call JSON å­—ç¬¦ä¸²ä¸­å°è¯•è§£æ name å­—æ®µï¼Œç”¨äºç”Ÿæˆå ä½ observationã€‚å¤±è´¥åˆ™è¿”å›ç©ºä¸²ã€‚"""
    try:
        # å°è¯•ç²¾ç¡®è§£æ JSONï¼ˆå¸¸è§ä¸º {"name":..., "arguments":{...}}ï¼‰
        obj = json.loads(call_str)
        if isinstance(obj, dict):
            name = obj.get("name")
            if isinstance(name, str):
                return name
    except Exception:
        pass

    # fallbackï¼šç”¨æ­£åˆ™å¼±åŒ¹é… "name": "xxx"
    m = re.search(r"\"name\"\s*:\s*\"([^\"]+)\"", call_str)
    return m.group(1) if m else ""


def build_observation_from_tool_response(resp_str: str) -> str:
    # å…è®¸ä¼ å…¥å¸¦ <tool_response> åŒ…è£¹çš„æ–‡æœ¬ï¼›å‰¥å£³åå†è§£æ
    # å¤ç”¨ä½ å·²æœ‰çš„æ­£åˆ™
    m = TOOL_RESPONSE_RE.search(resp_str)
    if m:
        resp_str = m.group(1).strip()

    try:
        obj = json.loads(resp_str)
        if isinstance(obj, dict):
            name = obj.get("name")
            content = obj.get("content")
            return json.dumps([{
                "type": "tool_result",
                "name": name,
                "content": content
            }], ensure_ascii=False)
        # è‹¥æœ‰çš„å·¥å…·ç›´æ¥è¿”å›æ•°ç»„ã€å­—ç¬¦ä¸²ï¼Œä¹ŸåŒ…æˆ raw ä»¥å…ä¸¢
        return json.dumps([{"type": "raw", "text": obj}], ensure_ascii=False)
    except Exception:
        return json.dumps([{"type": "raw", "text": resp_str}], ensure_ascii=False)


def parse_conversations(conversations):
    samples = []
    current_round = []
    pending_calls = []   # ç¼“å­˜ tool_call
    pending_resps = []   # ç¼“å­˜ tool_response

    def append_placeholder_gpt(round_):
        round_.append({"from": "gpt", "value": "Placeholder GPT"})
        return round_

    for msg in conversations:
        role = msg.get("from")
        value = msg.get("value", "")

        if role == "gpt":
            # åªæå– tool_callï¼ˆä¸å†é…å¯¹ responseï¼‰
            extracted_calls, _, _ = extract_calls_responses_and_text(value)
            for call_str in extracted_calls:
                pending_calls.append(call_str)

            # âš ï¸ è¿™é‡Œç›´æ¥è·³è¿‡ï¼Œä¸ç”Ÿæˆ observationï¼Œç­‰ tool æ¶ˆæ¯æ¥äº†å†é…å¯¹
            continue

        elif role == "tool":
            # æå– tool_response
            resp_strs = [m.group(1).strip() for m in TOOL_RESPONSE_RE.finditer(value)]
            if not resp_strs:
                # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œç›´æ¥åŸæ ·ä½œä¸º raw
                pending_resps.append(value)
            else:
                pending_resps.extend(resp_strs)

            # å°† call å’Œ response æŒ‰é¡ºåºé…å¯¹
            while pending_calls:
                call_str = pending_calls.pop(0)
                current_round.append({"from": "function_call", "value": call_str})

                if pending_resps:
                    resp_str = pending_resps.pop(0)
                    obs_val = build_observation_from_tool_response(resp_str)
                else:
                    tool_name = parse_tool_name_from_call(call_str)
                    obs_val = json.dumps([{
                        "type": "tool_result",
                        "name": tool_name,
                        "content": "[Stub] Placeholder response"
                    }], ensure_ascii=False)

                current_round.append({"from": "observation", "value": obs_val})

            continue

        elif role == "system":
            continue  # è·³è¿‡ system

        elif role == "human":
            # å¦‚æœæœ‰é—ç•™çš„æœªé…å¯¹ call â†’ å¡«å…… stub
            while pending_calls:
                call_str = pending_calls.pop(0)
                current_round.append({"from": "function_call", "value": call_str})
                if pending_resps:
                    resp_str = pending_resps.pop(0)
                    obs_val = build_observation_from_tool_response(resp_str)
                else:
                    tool_name = parse_tool_name_from_call(call_str)
                    obs_val = json.dumps([{
                        "type": "tool_result",
                        "name": tool_name,
                        "content": "[Stub] Placeholder response"
                    }], ensure_ascii=False)
                current_round.append({"from": "observation", "value": obs_val})

            if current_round:
                # ç»“æŸä¸€è½®å¯¹è¯
                current_round = append_placeholder_gpt(current_round)
                samples.append({"conversations": current_round})
                current_round = []

            current_round.append({"from": "human", "value": value})

        elif role == "function_call":
            # å°‘æ•°åœºæ™¯ tool_call å•ç‹¬å‡ºç°
            pending_calls.append(value)

    # ğŸ”š æœ€åä¸€è½®æ”¶å°¾
    while pending_calls:
        call_str = pending_calls.pop(0)
        current_round.append({"from": "function_call", "value": call_str})
        if pending_resps:
            resp_str = pending_resps.pop(0)
            obs_val = build_observation_from_tool_response(resp_str)
        else:
            tool_name = parse_tool_name_from_call(call_str)
            obs_val = json.dumps([{
                "type": "tool_result",
                "name": tool_name,
                "content": "[Stub] Placeholder response"
            }], ensure_ascii=False)
        current_round.append({"from": "observation", "value": obs_val})

    if current_round:
        current_round = append_placeholder_gpt(current_round)
        samples.append({"conversations": current_round})

    return samples



def transform_jsonl_file(in_path: Path, overwrite_in_place: bool = True, backup: bool = True) -> Path:
    """æµå¼è¯»å–å·¨å¤§ JSONL æ–‡ä»¶ï¼Œé€è¡Œè§„èŒƒåŒ– conversationsï¼Œå¹¶å†™å›ã€‚
    - å†™å…¥ä¸´æ—¶æ–‡ä»¶ .tmp
    - æˆåŠŸåå¯é€‰é‡å‘½åä¸ºåŸæ–‡ä»¶ï¼ŒåŸæ–‡ä»¶é‡å‘½åä¸º .bak
    è¿”å›è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
    """
    out_dir = Path("data/2_converted")
    out_dir.mkdir(parents=True, exist_ok=True)
    tmp_path = out_dir / in_path.with_suffix(".jsonl").name
    print(f"[INFO] å†™å…¥è·¯å¾„: {tmp_path}")
    total = 0
    fixed = 0
    with in_path.open("r", encoding="utf-8") as fin, tmp_path.open("w", encoding="utf-8") as fout:
        for line in fin:
            total += 1
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
            except Exception:
                # éæ³•è¡Œï¼ŒåŸæ ·å†™å›
                fout.write(line + "\n")
                continue

            if isinstance(obj, dict) and obj.get("conversations"):
                new_obj = parse_conversations(obj["conversations"])
                fixed += 1
            else:
                new_obj = obj

            fout.write(json.dumps(new_obj, ensure_ascii=False) + "\n")

    print(f"[INFO] å·²å¤„ç† {total} è¡Œï¼Œå…¶ä¸­è§„èŒƒåŒ– {fixed} è¡Œ")
import re

def append_placeholder_gpt(conversations: list) -> list:
    """
    åœ¨ conversations å°¾éƒ¨æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆ gpt å›å¤ï¼š
    - è‹¥æ—  â†’ æ·»åŠ å ä½ gptï¼›
    """
    conversations.append({
            "from": "gpt",
            "value": "Placeholder GPT"
        })
    return conversations

def main():
    parser = argparse.ArgumentParser(description="Normalize Tool-Calling conversations JSONL to eval format (streaming)")
    parser.add_argument("--input", default="data/1_raw/Tool-Calling-Dataset-UIGEN-X.jsonl")
    parser.add_argument("--no-backup", action="store_true", help="Do not create .bak backup when overwriting")
    parser.add_argument("--no-overwrite", action="store_true", help="Do not overwrite input; keep .tmp output")
    args = parser.parse_args()

    in_path = Path(args.input)
    if not in_path.exists():
        raise SystemExit(f"[FATAL] è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{in_path}")

    out_path = transform_jsonl_file(
        in_path,
        overwrite_in_place=not args.no_overwrite,
        backup=not args.no_backup,
    )

if __name__ == "__main__":
    main()
